{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "代码测试_降低维度.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOmCV/VYVkVgmkeVay8YzHW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yemanzhongting/JointSensing/blob/master/%E9%99%8D%E4%BD%8E%E7%BB%B4%E5%BA%A6_%E4%BF%AE%E6%94%B9%E5%85%A8%E8%BF%9E%E6%8E%A5%E5%B1%82%E7%9A%84%E7%A5%9E%E7%BB%8F%E5%85%83%E4%B8%AA%E6%95%B0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OvWuVzy2t_Ar"
      },
      "source": [
        "import torchvision\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "# model = torchvision.models.vgg16(pretrained=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5vaQKnrSuBMN",
        "outputId": "73e96dd0-9e0f-44d0-f331-45683a369167"
      },
      "source": [
        "import torch as t\n",
        "from torch import nn\n",
        "\n",
        "# in_features由输入张量的形状决定，out_features则决定了输出张量的形状 \n",
        "connected_layer = nn.Linear(in_features = 1000, out_features = 100)\n",
        "\n",
        "# 假定输入的图像形状为[64,64,3]\n",
        "\n",
        "output = connected_layer(a) # 调用全连接层\n",
        "print(output.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 100])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W9FilaeTyiMt",
        "outputId": "c5fbeb6b-c14d-419c-ef62-fd6b49fcdc4d"
      },
      "source": [
        "model = torchvision.models.vgg16(pretrained=True)\n",
        "\n",
        "a=torch.zeros(1,3,224,224)\n",
        "#我们枚举整个网络的所有层\n",
        "for i,m in enumerate(model.modules()):\n",
        "\t#print(i)\n",
        "\t#print(m)\n",
        "\t#让网络依次经过和原先结构相同的层，我们就可以获取想要的层的输出\n",
        "\tif isinstance(m, nn.Conv2d) or isinstance(m, nn.BatchNorm2d) or\\\n",
        "\t\t\tisinstance(m, nn.ReLU) or isinstance(m, nn.MaxPool2d) or isinstance(m, nn.AdaptiveAvgPool2d):\n",
        "\t\tprint(m)\n",
        "\t\ta= m(a)\n",
        "\t\tprint('111')\n",
        "\t#我只想要第一个全连接层的输出\n",
        "\telif isinstance(m, nn.Linear):\n",
        "\t\tprint(m)\n",
        "\t\tprint('222')\t\n",
        "\t\t#和源代码一样，将他展平成一维的向量\n",
        "\t\ta = torch.flatten(a, 1)\n",
        "\t\t#获取第一个全连接层的输出\n",
        "\t\ta= m(a)\n",
        "\t\t# break\n",
        "connected_layer = nn.Linear(in_features = 1000, out_features = 100)\n",
        "output = connected_layer(a) # 调用全连接层\n",
        "print(output)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "111\n",
            "ReLU(inplace=True)\n",
            "111\n",
            "Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "111\n",
            "ReLU(inplace=True)\n",
            "111\n",
            "MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "111\n",
            "Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "111\n",
            "ReLU(inplace=True)\n",
            "111\n",
            "Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "111\n",
            "ReLU(inplace=True)\n",
            "111\n",
            "MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "111\n",
            "Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "111\n",
            "ReLU(inplace=True)\n",
            "111\n",
            "Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "111\n",
            "ReLU(inplace=True)\n",
            "111\n",
            "Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "111\n",
            "ReLU(inplace=True)\n",
            "111\n",
            "MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "111\n",
            "Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "111\n",
            "ReLU(inplace=True)\n",
            "111\n",
            "Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "111\n",
            "ReLU(inplace=True)\n",
            "111\n",
            "Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "111\n",
            "ReLU(inplace=True)\n",
            "111\n",
            "MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "111\n",
            "Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "111\n",
            "ReLU(inplace=True)\n",
            "111\n",
            "Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "111\n",
            "ReLU(inplace=True)\n",
            "111\n",
            "Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "111\n",
            "ReLU(inplace=True)\n",
            "111\n",
            "MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "111\n",
            "AdaptiveAvgPool2d(output_size=(7, 7))\n",
            "111\n",
            "Linear(in_features=25088, out_features=4096, bias=True)\n",
            "222\n",
            "ReLU(inplace=True)\n",
            "111\n",
            "Linear(in_features=4096, out_features=4096, bias=True)\n",
            "222\n",
            "ReLU(inplace=True)\n",
            "111\n",
            "Linear(in_features=4096, out_features=1000, bias=True)\n",
            "222\n",
            "tensor([[-0.8315, -0.2027,  0.2047,  0.7270, -0.2220, -0.2637, -0.5462, -0.1649,\n",
            "         -0.0185, -0.1704, -0.3096, -0.8170,  0.2294,  0.2861, -1.4493,  0.2838,\n",
            "         -0.1705, -0.0799, -0.3290, -0.4294, -0.5723, -0.3561,  0.4985,  0.6553,\n",
            "         -0.4865, -0.8099, -0.1613, -0.8135,  0.5066,  0.7788, -0.1579, -0.5150,\n",
            "          0.8990,  0.5600,  1.9894,  0.2922, -1.9394, -0.3679, -1.7239,  0.2199,\n",
            "         -0.1514, -0.7296, -0.1376, -0.9607, -0.3579,  0.3708,  1.0190,  0.4798,\n",
            "         -0.3525,  0.7126, -0.5491, -0.0889, -0.2775, -0.5410, -0.1312, -0.4977,\n",
            "          0.7248, -0.1717, -0.5809,  0.2746,  0.4440,  0.1944, -0.8818, -0.1836,\n",
            "         -0.0336, -0.9941, -1.0419, -0.0524,  0.0960, -0.4120, -0.1973, -0.0490,\n",
            "          0.6325,  0.0214,  0.7840,  0.5535, -0.1333,  1.1552,  0.0088,  0.5132,\n",
            "         -0.5373, -0.6385, -1.6130, -0.4582,  0.4424,  0.8777,  0.5377,  0.6270,\n",
            "          0.4914, -0.0796, -0.6433,  0.8495, -0.7576,  0.1609, -0.2947, -0.6276,\n",
            "          0.2549,  0.7218,  0.2872, -0.1835]], grad_fn=<AddmmBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qDwO_epyuBjM"
      },
      "source": [
        "resnet = torchvision.models.vgg16(pretrained=True)\n",
        "# 原本为1000类，改为10类\n",
        "resnet.fc = torch.nn.Linear(1000, 100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "415xzed_0Cgy"
      },
      "source": [
        "a=torch.zeros(1,3,224,224)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NGkor6zgyhNf",
        "outputId": "bccb8434-a454-4a40-a10f-76cd57d3615e"
      },
      "source": [
        "for i,m in enumerate(resnet.modules()):\n",
        "\t#print(i)\n",
        "\t#print(m)\n",
        "\t#让网络依次经过和原先结构相同的层，我们就可以获取想要的层的输出\n",
        "\tif isinstance(m, nn.Conv2d) or isinstance(m, nn.BatchNorm2d) or\\\n",
        "\t\t\tisinstance(m, nn.ReLU) or isinstance(m, nn.MaxPool2d) or isinstance(m, nn.AdaptiveAvgPool2d):\n",
        "\t\tprint(m)\n",
        "\t\ta= m(a)\n",
        "\t\tprint('111')\n",
        "\t#我只想要第一个全连接层的输出\n",
        "\telif isinstance(m, nn.Linear):\n",
        "\t\tprint(m)\n",
        "\t\tprint('222')\t\n",
        "\t\t#和源代码一样，将他展平成一维的向量\n",
        "\t\ta = torch.flatten(a, 1)\n",
        "\t\t#获取第一个全连接层的输出\n",
        "\t\ta= m(a)\n",
        "\t\t# break\n",
        "print(a)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "111\n",
            "ReLU(inplace=True)\n",
            "111\n",
            "Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "111\n",
            "ReLU(inplace=True)\n",
            "111\n",
            "MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "111\n",
            "Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "111\n",
            "ReLU(inplace=True)\n",
            "111\n",
            "Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "111\n",
            "ReLU(inplace=True)\n",
            "111\n",
            "MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "111\n",
            "Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "111\n",
            "ReLU(inplace=True)\n",
            "111\n",
            "Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "111\n",
            "ReLU(inplace=True)\n",
            "111\n",
            "Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "111\n",
            "ReLU(inplace=True)\n",
            "111\n",
            "MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "111\n",
            "Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "111\n",
            "ReLU(inplace=True)\n",
            "111\n",
            "Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "111\n",
            "ReLU(inplace=True)\n",
            "111\n",
            "Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "111\n",
            "ReLU(inplace=True)\n",
            "111\n",
            "MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "111\n",
            "Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "111\n",
            "ReLU(inplace=True)\n",
            "111\n",
            "Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "111\n",
            "ReLU(inplace=True)\n",
            "111\n",
            "Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "111\n",
            "ReLU(inplace=True)\n",
            "111\n",
            "MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "111\n",
            "AdaptiveAvgPool2d(output_size=(7, 7))\n",
            "111\n",
            "Linear(in_features=25088, out_features=4096, bias=True)\n",
            "222\n",
            "ReLU(inplace=True)\n",
            "111\n",
            "Linear(in_features=4096, out_features=4096, bias=True)\n",
            "222\n",
            "ReLU(inplace=True)\n",
            "111\n",
            "Linear(in_features=4096, out_features=1000, bias=True)\n",
            "222\n",
            "Linear(in_features=1000, out_features=100, bias=True)\n",
            "222\n",
            "tensor([[-1.0493,  0.1981, -0.2785,  0.1414, -0.9924,  1.0515,  0.1611,  0.2993,\n",
            "          0.1429, -0.2687,  0.8236,  0.3058, -0.2114,  0.1190, -0.3133, -0.4744,\n",
            "         -0.2098,  0.0545, -0.2930,  0.3161, -0.0170,  0.2055, -0.0119,  0.7989,\n",
            "          0.8607, -0.6861, -0.9141, -0.0535,  0.8061,  0.1250,  0.9854,  0.7081,\n",
            "          0.2286, -0.2436, -0.4031, -0.4827,  0.9753, -0.4322,  0.5352,  0.3338,\n",
            "          0.2950, -1.0168,  0.1201,  0.1762, -0.1529, -0.1505,  0.7098,  0.7326,\n",
            "         -0.2595,  0.1557, -0.0136,  0.7545,  0.1344,  0.1641,  0.6525, -0.3104,\n",
            "          0.4617,  0.9178,  0.1135,  0.8505,  0.4521,  0.5238,  0.2374, -0.9734,\n",
            "         -0.0752,  0.2266, -0.3336,  0.0255,  0.0121,  0.4830, -0.5096, -0.8046,\n",
            "          0.2953, -1.0095,  1.2356,  0.5345, -0.9717, -0.5351,  0.7133, -0.5176,\n",
            "          0.7348, -0.3398, -0.4621, -0.2856, -0.2081,  0.0992, -1.1200,  0.1365,\n",
            "          0.3765,  0.5672, -0.7026,  0.6646,  0.4576, -0.7713, -0.3637, -0.6366,\n",
            "          0.8264,  0.2341, -0.2141, -1.0093]], grad_fn=<AddmmBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_b3DF50X0T9b"
      },
      "source": [
        "AAA=[-0.8315, -0.2027,  0.2047,  0.7270, -0.2220, -0.2637, -0.5462, -0.1649,\n",
        "         -0.0185, -0.1704, -0.3096, -0.8170,  0.2294,  0.2861, -1.4493,  0.2838,\n",
        "         -0.1705, -0.0799, -0.3290, -0.4294, -0.5723, -0.3561,  0.4985,  0.6553,\n",
        "         -0.4865, -0.8099, -0.1613, -0.8135,  0.5066,  0.7788, -0.1579, -0.5150,\n",
        "          0.8990,  0.5600,  1.9894,  0.2922, -1.9394, -0.3679, -1.7239,  0.2199,\n",
        "         -0.1514, -0.7296, -0.1376, -0.9607, -0.3579,  0.3708,  1.0190,  0.4798,\n",
        "         -0.3525,  0.7126, -0.5491, -0.0889, -0.2775, -0.5410, -0.1312, -0.4977,\n",
        "          0.7248, -0.1717, -0.5809,  0.2746,  0.4440,  0.1944, -0.8818, -0.1836,\n",
        "         -0.0336, -0.9941, -1.0419, -0.0524,  0.0960, -0.4120, -0.1973, -0.0490,\n",
        "          0.6325,  0.0214,  0.7840,  0.5535, -0.1333,  1.1552,  0.0088,  0.5132,\n",
        "         -0.5373, -0.6385, -1.6130, -0.4582,  0.4424,  0.8777,  0.5377,  0.6270,\n",
        "          0.4914, -0.0796, -0.6433,  0.8495, -0.7576,  0.1609, -0.2947, -0.6276,\n",
        "          0.2549,  0.7218,  0.2872, -0.1835]\n",
        "BBB=[-1.0493,  0.1981, -0.2785,  0.1414, -0.9924,  1.0515,  0.1611,  0.2993,\n",
        "          0.1429, -0.2687,  0.8236,  0.3058, -0.2114,  0.1190, -0.3133, -0.4744,\n",
        "         -0.2098,  0.0545, -0.2930,  0.3161, -0.0170,  0.2055, -0.0119,  0.7989,\n",
        "          0.8607, -0.6861, -0.9141, -0.0535,  0.8061,  0.1250,  0.9854,  0.7081,\n",
        "          0.2286, -0.2436, -0.4031, -0.4827,  0.9753, -0.4322,  0.5352,  0.3338,\n",
        "          0.2950, -1.0168,  0.1201,  0.1762, -0.1529, -0.1505,  0.7098,  0.7326,\n",
        "         -0.2595,  0.1557, -0.0136,  0.7545,  0.1344,  0.1641,  0.6525, -0.3104,\n",
        "          0.4617,  0.9178,  0.1135,  0.8505,  0.4521,  0.5238,  0.2374, -0.9734,\n",
        "         -0.0752,  0.2266, -0.3336,  0.0255,  0.0121,  0.4830, -0.5096, -0.8046,\n",
        "          0.2953, -1.0095,  1.2356,  0.5345, -0.9717, -0.5351,  0.7133, -0.5176,\n",
        "          0.7348, -0.3398, -0.4621, -0.2856, -0.2081,  0.0992, -1.1200,  0.1365,\n",
        "          0.3765,  0.5672, -0.7026,  0.6646,  0.4576, -0.7713, -0.3637, -0.6366,\n",
        "          0.8264,  0.2341, -0.2141, -1.0093]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cp9LN5GO0gAp"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}